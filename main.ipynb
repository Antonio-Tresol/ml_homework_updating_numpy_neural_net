{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.config import *\n",
    "from data.dataset import *\n",
    "from report.dumps import *\n",
    "from nn.model import model\n",
    "from nn.funcs import *\n",
    "import numpy as np\n",
    "\n",
    "def test(nn, ds, verbose=False, phase=\"Validation\", acc_func=batch_hits):\n",
    "    ds.reset()\n",
    "    hits = 0\n",
    "    mean_loss = 0\n",
    "    while not(ds.iter_done()):\n",
    "        x, y = ds.next()\n",
    "        o, batch_loss = nn.forward(x, y, train=False)\n",
    "        hits += np.sum(acc_func(o, y))\n",
    "        mean_loss += np.sum(batch_loss)\n",
    "        #if verbose:\n",
    "        #    print(\"Loss: \" + str(mean_loss), \" Predicted: \" + str(o), \" Expected: \" + str(y))\n",
    "    accuracy = float(hits) / float(ds.size)\n",
    "    mean_loss = float(mean_loss) / float(ds.size)\n",
    "    if verbose:\n",
    "        print(f\"{phase} Accuracy: {str(accuracy)} Mean Loss {str(mean_loss)}\")\n",
    "    return accuracy, mean_loss\n",
    "\n",
    "def train(nn, hp, val_hist, train_hist, logger, acc_func=batch_hits):\n",
    "    cur_epoch = 1\n",
    "    cur_iter = 1\n",
    "    for i in range(1, hp.epochs+1):\n",
    "        train_loss = 0\n",
    "        hits = 0\n",
    "        cur_trained = 0\n",
    "        while not(hp.ds_train.iter_done()):\n",
    "            x, y = hp.ds_train.next()\n",
    "            #print(y)\n",
    "            o, batch_loss = nn.forward(x, y)\n",
    "            nn.backward(y,o)\n",
    "            nn.update(hp.lr)\n",
    "\n",
    "            hits += np.sum(acc_func(o, y))\n",
    "            cur_trained += len(x)\n",
    "            train_loss += np.sum(batch_loss)\n",
    "\n",
    "            if cur_iter % hp.validate_every_no_of_batches == 0:\n",
    "\n",
    "                train_accuracy = float(hits) / float(cur_trained)\n",
    "                train_loss = float(train_loss) / float(cur_trained)\n",
    "                train_hist.add(cur_iter, train_loss, train_accuracy)\n",
    "                logger.write( (cur_epoch, \"Training\", cur_iter, train_accuracy, train_loss) )\n",
    "                hits = 0\n",
    "                train_loss = 0\n",
    "\n",
    "                val_accuracy, val_loss = test(nn, hp.ds_val, True, acc_func=acc_func)\n",
    "                val_hist.add(cur_iter, val_loss, val_accuracy)\n",
    "                logger.write( (cur_epoch, \"Val\", cur_iter, val_accuracy, val_loss) )\n",
    "            cur_iter+=1\n",
    "        cur_epoch+=1\n",
    "        hp.ds_train.reset()\n",
    "    return val_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = hyperparams(ConfigEnum.SIN)\n",
    "\n",
    "nn = model(hp.input_size, hp.output_size, hp.hidden_shapes, sigmoid, sigmoid_grad, has_dropout=hp.has_dropout, dropout_perc=hp.dropout_perc, loss_type=\"mse\")\n",
    "\n",
    "val_hist = historian()\n",
    "train_hist = historian()\n",
    "logger = nnlogger(hp.output_log, (\"Epoch\", \"Phase\", \"Iteration\", \"Accuracy\", \"Loss\") )\n",
    "train(nn, hp, val_hist, train_hist, logger, acc_func=mean_absolute_error)\n",
    "test(nn=nn, ds=hp.ds_test, verbose=True, phase=\"Test\", acc_func=mean_absolute_error)\n",
    "nnplotter.view(val_hist, train_hist) #see results on plot\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = hyperparams(ConfigEnum.SIN)\n",
    "\n",
    "nn = model(hp.input_size, hp.output_size, hp.hidden_shapes, tanh, tanh_grad, has_dropout=hp.has_dropout, dropout_perc=hp.dropout_perc, loss_type=\"mse\")\n",
    "\n",
    "val_hist = historian()\n",
    "train_hist = historian()\n",
    "logger = nnlogger(hp.output_log, (\"Epoch\", \"Phase\", \"Iteration\", \"Accuracy\", \"Loss\") )\n",
    "train(nn, hp, val_hist, train_hist, logger, acc_func=mean_absolute_error)\n",
    "test(nn, hp.ds_test, verbose=True, phase=\"Test\", acc_func=mean_absolute_error)\n",
    "nnplotter.view(val_hist, train_hist) #see results on plot\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanh Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = hyperparams(ConfigEnum.SIN)\n",
    "\n",
    "nn = model(hp.input_size, hp.output_size, hp.hidden_shapes, tanh_np, tanh_grad_np, has_dropout=hp.has_dropout, dropout_perc=hp.dropout_perc, loss_type=\"mse\")\n",
    "\n",
    "val_hist = historian()\n",
    "train_hist = historian()\n",
    "logger = nnlogger(hp.output_log, (\"Epoch\", \"Phase\", \"Iteration\", \"Accuracy\", \"Loss\") )\n",
    "train(nn, hp, val_hist, train_hist, logger, acc_func=mean_absolute_error)\n",
    "test(nn, hp.ds_test, verbose=True, phase=\"Test\", acc_func=mean_absolute_error)\n",
    "nnplotter.view(val_hist, train_hist) #see results on plot\n",
    "logger.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
